---
layout : post
title : '[빅데이터를 지탱하는 기술] 3-1 대규모 분산 처리의 프레임워크'
subtitle : '[빅데이터를 지탱하는 기술] 정리'
gh-repo: junhong625/Study
gh-badge: [star, fork, follow]
tags : [빅데이터를 지탱하는 기술, Study]
comments: true
---

# 3-1 대규모 분산 처리의 프레임워크
- - - 

## 구조화 데이터와 비구조화 데이터
- **스키마(schema)** : SQL로 데이터를 집계하는 경우, 테이블의 칼럼 명과 데이터형, 테이블 간의 관계 등을 뜻함
- **구조화된 데이터(structured data)** : 스키마가 명확하게 정의된 데이터
    - 기존의 데이터 웨어하우스에서는 항상 구조화된 데이터로 축적하는 것이 일반적
- **비구조화 데이터(unstructed data)** : 스키마가 없는 데이터
    - 자연 언어로 작성된 텍스트 데이터와 이미지, 동영상 등의 미디어 데이터
    - SQL로 제대로 집계할 수 없음
- **데이터 레이크의 개념** : 비구조화 데이터를 분산 스토리지 등에 저장하고 그것을 분산 시스템에서 처리하는 것
- 데이터를 가공하는 과정에서 스키마를 정의하고, 구조화된 데이터로 변환함으로써 다른 데이터와 마찬가지로 분석할 수 있음
<img height=400 src="https://user-images.githubusercontent.com/83000975/166099202-efad36df-c6e8-441d-8a9b-c96933955882.jpeg">

<sub><b>[구조화 데이터, 비구조화 데이터, 스키마리스(반구조화 데이터)]</b></sub>
<br>
<br>

### 1) 스키마리스 데이터
- **스키마리스 데이터(schemaless data)** : 기본 서식은 있지만, 스키마가 정의 안 된 데이터
    - CSV, JSON, XML 등의 데이터는 서식은 정해져 있지만, 칼럼 수나 데이터형은 명확하지 않아 스키마리스 데이터라고 불림.
        - 엄밀히 말하면 JSON과 XML 등의 포맷은 **반구조화 데이터(semi-structed data)**라고 할 수 있음
    - 몇몇 NoSQL 데이터베이스는 스키마리스 데이터에 대응하고 있으며, 데이터 레이크에서는 대량으로 축적된 스키마리스 데이터를 효율적으로 처리하도록 요구를 종종 함
    - JSON 형식을 이용하는 경우가 특히 많음 
    - JSON은 JSON 그대로 저장하고 거기서 데이터 분석에 필요한 필드만을 추출하는 편이 간단하기 때문
    - 원래의 데이터만 그대로 보존되어 있으면, 처음부터 모든 필드를 추출하지 않고도 나중에 얼마든지 추가 정보를 끄낼 수 있다.
<br>
<br>

### 2) 데이터 구조화의 파이프 라인
- 데이터 소스에서 수집된 비구조화 데이터 또는 스키마리스 데이터는 처음에 분산 스토리지에 보존됨
    - 웹 서버의 로그 파일과 업무용 데이터베이스에서 추출한 마스터 데이터 등이 포함되어 있음
<img height=400 src="https://user-images.githubusercontent.com/83000975/166100127-c04d460e-89a6-429a-9172-87be98282ff9.jpeg">

<sub><b>[데이터 구조화의 파이프라인]</b></sub>

- 분산 스토리지에 수집된 데이터는 명확한 스키마를 갖지 않는 것도 많으므로 그냥 SQL 집계할 수 없음
    - 따라서 먼저 필요한 것은 스키마를 명확하게 한 테이블 형식의 **구조화 데이터**로 변환하는 것임
- 일반적으로 구조화 데이터는 데이터의 압축률을 높이기 위해 열 지향 스토리지로 저장함
    - 즉, MPP 데이터베이스로 전송하거나 Hadoop 상에서 열 지향 스토리지 형식으로 변환함
- 구조화 데이터 중 시간에 따라 증가하는 데이터를 팩트 테이블, 그에 따른 부속 데이터를 디멘전 테이블로 취급함
    - 이 단계에서는 테이블을 조인하지 않음
<br>
<br>

### 3) 열 지향 스토리지의 작성
- MPP 데이터베이스의 경우, 제품에 따라 스토리지의 형식이 고정되어 있어 사용자가 그 상세를 몰라도 괜찮지만
- Hadoop에서는 사용자가 직접 열 지향 스토리지의 형식을 선택하고 자신이 좋아하는 쿼리 안에서 집계 가능
    - Hadoop에서 사용할 수 있는 열 지향 스토리지의 종류 :
        1. Apache ORC : 구조화 된 데이터를 위한 열 지향 스토리지로 처음에 스키마를 정한 후 데이터를 저장
        2. Apache Parquet : 스키마리스에 가까운 데이터 구조로 되어 있어 JSON과 같은 뒤얽힌 데이터도 그대로 저장 가능
- 비구조화 데이터를 읽어 들여 열 지향 스토리지로 변환하는 과정에서는 데이터의 가공 및 압축을 위해 많은 컴퓨터 리소스가 소비됨
    - 그래서 사용되는 것이 Hadoop과 Spark 등의 분산 처리 프레임워크
<br>
<br>

## Hadoop - 분산 데이터 처리의 공통 플랫폼
- Hadoop의 시작은 오픈 소스 웹 크롤러인 Nutch를 위한 분산 파일 시스템으로 2003년경부터 개발을 시작했고 2006년 단일 프로젝트로 독립해서 Apache Hadoop으로 배포됨
- **Hadoop** : 단일 소프트웨어가 아니라 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체
    - 2013년에 배포된 Hadoop2부터 YARN이라고 불리는 새로운 리소스 관리자 상에서 복수의 분산 애플리케이션이 동작하는 구성으로 되어, 대규모 분산시스템을 구축하기 위한 공통 플랫폼의 역할을 담당

|시기|이벤트|
|:--|:--|
|2003년|Nutch 프로젝트 발족|
|2004년|Google MapReduce 논문|
|2006년|Apache Hadoop 프로젝트 발족|
|2011년|Apache Hadoop 1.0.0 배포|
|2013년|Apache Hadoop 2.2.0 배포(YARN 대응)|
|2014년|Apache Spark 1.0.0 배포|
|2016년|Apache Flink 1.0.0 배포|
|2016년|Apache Mesos 1.0.0 배포|

<sub><b>[Hadoop과 그 주변 프로젝트의 역사(2016년까지)]</b></sub>
<br>
<br>

### 1) 분산 시스템의 구성 요소 HDFS, YARN, MapReduce
- **Hadoop의 기본 구성 요소** : 
    1. 분산 파일 시스템(distributed file system) : HDFS(Hadoop Distributed File System)
    2. 리소스 관리자(resource manager) : YARN(Yet Another Resource Negotiator)
    3. 분산 데이터 처리(distributed data processing) : MapReduce
- 그 외의 프로젝트는 Hadoop 본체와는 독립적으로 개발되어 Hadoop을 이용한 분산 애플리케이션으로 동작함
- 모든 분산 시스템이 Hadoop에 의존하는 것이 아니라, Hadoop을 일부만 사용하거나 혹은 전혀 이용하지 않는 구성도 있음
    - 예를 들어 분산 파일 시스템으로 HDFS를 사용하면서 리소스 관리자는 Mesos, 분산 데이터 처리에는 Spark를 사용하는 구성도 가능함
- 자신에게 맞는 것을 선택 조합하여 시스템을 구성하는 것이 Hadoop을 중심으로 하는 데이터 처리의 특징
<br>
<br>

### 2) 분산 파일 시스템과 리소스 관리자 HDFS, YARN
- Hadoop에서 처리되는 데이터 대부분은 분산 파일 시스템인 HDFS에 저장됨
    - 이것은 네트워크에 연결된 파일 서버와 같은 존재이지만, 다수의 컴퓨터에 파일을 복사하여 중복성을 높인다는 특징이 있음
- CPU나 메모리 등의 계산 리소스는 리소스 매니저인 YARN에 의해 관리됨
    - YARN은 애플리케이션이 사용하는 CPU 코어와 메모리를 **컨테이너**라 불리는 단위로 관리함
    - **YARN의 컨테이너** : 어떤 호스트에서 어떤 프로세스를 실행시킬 것인지 결정하는 애플리케이션 수준의 기술
- Hadoop에서 분산 애플리케이션을 실행하면 YARN이 클러스터 전체의 부하를 보고 비어 있는 호스트부터 컨테이너를 할당함
<img height=400 src="https://user-images.githubusercontent.com/83000975/166101989-4d359c62-cef2-4450-8745-3462383994f7.jpeg">

<sub><b>[Hadoop에 의한 리소스 관리]</b></sub>

- HDFS는 분산 시스템의 스토리지를 관리하여 데이터가 항상 여러 컴퓨터에 복사되도록 함.
- YARN은 CPU와 메모리를 관리하고 리소스에 여유가 있는 컴퓨터에서 프로그램을 실행함
- HDFS와 YARN 이 둘은 서로 연계해서 동작하게 되어 있기 때문에 분산 애플리케이션을 되도록 데이터에서 가까운 노드에서 실행하게 하는 것도 가능함
- 분산 시스템은 많은 계산 리소스를 소비하지만, 호스트의 수에 따라 사용할 수 있는 리소스의 상한이 결정됨
    - 한정된 리소스로 다수의 분산 애플리케이션이 동시에 실행되므로 애플리케이션 간에 리소스 쟁탈이 발생함
- 리소스 관리자는 모든 애플리케이션이 차질없이 실행되도록 각 애플리케이션에 얼마만큼의 리소스를 할당할지 관리하여 제어함
- 리소스 관리자를 사용하면 애플리케이션마다 실행의 우선순위를 결정할 수 있음
    - 그다지 중요하지 않은 배치 처리에는 낮은 우선순위를 부여함으로써 아무도 리소스를 사용하지 않을 경우에만 실행되도록 함
    - 우선되는 작업부터 실행함으로써 한정된 리소스를 낭비 없이 활용하며 데이터 처리를 진행할 수 있음
<br>
<br>

### 3) 분산 데이터 처리 및 쿼리 엔진 MapReduce, Hive
- **MapReduce** : YARN 상에서 동작하는 분산 애플리케이션 중 하나이며 분산 시스템에서 데이터 처리를 실행하는데 사용됨
    - 임의의 자바 프로그램을 실행시킬 수 있기 때문에 비구조화 데이터를 가공하는데 적합함
    - 원래 대량의 데이터를 배치 처리하기 위한 시스템임
        - 작은 프로그램을 실행하려면 오버헤드가 너무 크기 때문에 금방 끝나버리는 쿼리 실행에는 적합하지 않음
- **Hive** : SQL 등의 쿼리 언어에 의한 데이터 집계가 목적인 쿼리 엔진들 중 하나
    - 쿼리를 자동으로 MapReduce 프로그램으로 변환하는 소프트웨어로 개발됨
    - 초기 Hive의 실행 특성은 MapReduce에 의존하고 있었으며, 이것은 장점이자 단점이었음
        - MapReduce를 계승한 만큼 시간이 걸리는 배치 처리에는 적합하나, 애드 혹 쿼리를 여러 번 실행하는 데는 부적합함
<br>
<br>

### 4) Hive on Tez
- **Apache Tez** : Hive를 가속화하기 위한 노력의 하나로 개발된 것
    - 기존의 MapReduce를 대체할 목적으로 개발된 프로젝트
    - MapReduce에 있던 몇 가지 단점을 해소함으로써 고속화를 실현함
        - MapReduce 프로그램에서는 1회의 MapReduce 스테이지가 끝날 때까지 다음의 처리를 진행할 수 없던 것은 Tez에서는 종료를 기다리지 않고 처리가 끝난 데이터를 차례대로 후속 처리에 전달함으로써 쿼리 전체의 실행 시간을 단축함
- **Hive on Tez** : 현재의 Hive는 MapReduce뿐만 아니라 Tez를 사용해도 동작하게 재작성되어 있어 **Hive on Tez**라고 불림
    - Tez에서는 불필요한 단계가 감소되어 처리가 짧아짐과 동시에 스테이지 사이의 대기 시간이 없어 처리 전체가 동시에 실행되서 실행 시간이 단축됨
<img height=400 src="https://user-images.githubusercontent.com/83000975/166102627-1e03da1e-b376-497a-bca6-62376772459a.jpeg">

<sub><b>[Hive on Tez의 실행 과정]</b></sub>

- **Hive on MR** : 예전 Hive는 MapReduce의 처리 방식으로 진행하기에 **Hive on MR**로 불림
    - MapReduce에서는 데이터 처리의 스테이지가 바뀔 때 대기 시간이 있어서 복잡한 쿼리에서는 대기 시간만 증가함
<img height=400 src="https://user-images.githubusercontent.com/83000975/166102376-552d19f9-17ba-48e0-8a96-806c6d6b3049.jpeg">

<sub><b>[Hive on MR의 실행 과정]</b></sub>
<br>
<br>

### 5) 대화형 쿼리 엔진 Impala와 Presto
- **Apache Impala와 Presto** : 대화형의 쿼리 실행만 전문으로 하는 쿼리 엔진 중 대표적인 두 가지
- MapReduce와 Tez는 장시간의 배치 처리를 가정해 한정된 리소스를 유효하게 활용하도록 설계됨
- 대화형 쿼리 엔진으로는 순간 최대 속도를 높이기 위해 모든 오버헤드가 제거되어 사용할 수 있는 리소스를 최대한 활용하여 쿼리를 실행함
    - 그 결과 대화형 쿼리 엔진은 MPP 데이터베이스와 비교해도 손색없는 응답시간을 실현하고 있음
<img height=400 src="https://user-images.githubusercontent.com/83000975/166102794-220b244a-b7e8-4724-a25d-ad1e98b21a34.jpeg">

<sub><b>[Presto와 Impala의 실행 과정]</b></sub>
<br>
<hr>

- Hadoop에서는 성질이 다른 쿼리 엔진을 목적에 따라 구분함
- 대량의 비구조화 데이터를 가공하는 무거운 배치 처리에 높은 처리량으로 리소스를 활용할 수 있는 Hive를 활용
    - Hive를 활용하여 완성한 구조화 데이터를 대화식으로 집계할 때 지연이 적은 Impala와 Presto 등이 적합함
- **SQL-on-Hadoop** : Hadoop에서 개발된 다수의 쿼리 엔진을 지칭
    - MPP 데이터베이스의 기능을 따라잡지 못한 부분도 있지만, 분산 스토리지에 저장된 데이터를 신속하게 집계할 수 있는 점에서 우수함
<br>
<br>

## Spark - 인 메모리 형의 고속 데이터 처리
- **Apache Spark** : MapReduce보다 더 효율적인 데이터 처리를 실현하는 분산 데이터 처리 프레임워크
    - Hadoop의 연장선에 있는 Tez와 달리 Spark는 Hadoop과는 다른 독립된 프레임워크임
    - 특징 : 대량의 메모리를 활용하여 고속화를 실현함
        - MapReduce와 Tez는 개발 당시에 메모리 성능이 부족해 처리의 대부분을 읽고 쓰기에 사용함
        - 그러나 메모리 성능이 향상되며 **가능한 많은 데이터를 메모리상에 올린 상태로 두어 디스크에는 아무것도 기록하지 않는다**는 선택이 현실화 됨
            - 물론 디스크에 중간 데이터를 기록하지 않아 비정상 종료시 데이터는 사라져 버리지만 Spark는 실행 시간이 짧기에 그때는 다시 처리를 시도해서 잃어버린 중간 데이터를 다시 만들면 된다는 것이 Spark의 개념
            - 그리고 중간 데이터를 의도적으로 디스크 상에 캐시하는 것도 가능함
<img height=400 src="https://user-images.githubusercontent.com/83000975/166103435-5230ca4a-9b1b-45b7-b2d1-aaec271ec2e6.jpeg">

<sub><b>[Spark의 실행 과정]</b></sub>
<br>
<br>

### MapReduce 대체하기 (Spark의 입지)
- Spark는 Hadoop을 대체하는 것이 아닌 MapReduce를 대체하는 존재
    - 예를 들어 HDFS와 YARN등은 Spark에서 그대로 사용할 수 있음
    - Hadoop을 이용하지 않는 구성도 가능함
    - 분산 스토리지로 AWS S3를 이용하거나 분산 데이터베이스인 카산드라(cassandra)에서 데이터를 읽어 들이는 것도 가능함
- Spark의 실행은 자바 런타임이 필요하지만, Spark 상에서 실행되는 데이터 처리는 스크립트 언어를 사용할 수 있음
    - 자바, 스칼라, 파이썬, R언어에 대응하고 있으며 문서도 충실하기 때문에 도입하기 쉬움
- Spark는 **Spark SQL**과 **Spark Streaming**이라는 기능이 포함되어 있음
    - **Spark SQL** : Spark에서는 SQL로 쿼리를 실행하기 위한 Spark module
    - **Spark Streaming** : 스트림 처리를 수행하기 위한 Spark module
- **따라서 Spark는 대규모 배치 처리뿐만 아니라 SQL에 의한 대화형 쿼리 실행과 실시간 스트림 처리에 이르기까지 널리 이용되고 있음**
