---
layout : post
title : '[빅데이터를 지탱하는 기술] 1-2. 빅데이터 시대의 데이터 분석 기반'
subtitle : '[빅데이터를 지탱하는 기술] 정리'
gh-repo: junhong625/Study
gh-badge: [star, fork, follow]
tags : [빅데이터를 지탱하는 기술, Study]
comments: true
---

# 1-2 빅데이터 시대의 데이터 분석 기반
- - -

## [재입문] 빅데이터의 기술
### - 분산 시스템을 활용해서 데이터를 가공해 나가는 구조

### 1) 데이퍼 파이프라인 - 데이터 수집에서 워크플로 관리까지
- **데이터 수집에서 워크플로까지의 과정(차례대로 전달해나가는 데이터로 구성된 시스템)**
- 실현하고 싶은 목적에 따라 변화
<br>
<br>

### 2) 데이터 수집 - 벌크 형과 스트리밍 형의 데이터 전송
- **벌크 형**과 **스트리밍 형**의 두 가지 데이터 전송 방법
    - **벌크 형** : 이미 어딘가에 존재하는 데이터를 정리해 추출하는 방법(정기적으로 데이터를 수집)
    - **스트리밍 형** : 차례대로 생성되는 데이터를 실시간으로 보내는 방법(모바일 애플리케이션, 임베디드 장비 등에서 사용)
<br>
<img height=400 src="https://user-images.githubusercontent.com/83000975/164458406-6ca61a6b-93b6-4e42-a09c-208a00823dbc.jpeg">
<sub><b>[빅데이터를 위한 데이터 파이프라인</b></sub>
<br>
<br>

### 3) 스트림 처리와 배치 처리
- 과거에는 데이터 웨어하우스에서 다루는 데이터를 벌크 형 방법으로 이용됨
- 모바일 애플리케이션 등이 증가함에 따라 스트리밍 형이 주류가 됨
- **스트림 처리** : 스트리밍 형 방법으로 받은 데이터를 실시간으로 처리한 것
    - 장기적인 데이터 분석에 적합하지 않은 문제
- **배치 처리** : 벌크 형의 데이터를 받아 장기적인 데이터 분석을 진행하는 것
<br>
<br>

### 4) 분산 스토리지 
- 객체 스토리지, NoSQL 데이터베이스
- 여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템
- **객체 스토리지** : 대표적인 데이터 저장 방법(한 덩어리로 모인 데이터에 이름을 부여해서 파일로 저장),
                   예) Amazon S3
- NoSQL을 분산 스토리지로 사용 가능(단, 데이터 확장성이 높은 제품을 선택)
<br>
<br>

### 5) 분산 데이터 처리 
- 객체 스토리지, NoSQL 데이터베이스
- **MapReduce** : 분산 스토리지에 저장된 데이터 처리하기 위한 프레임워크
- 데이터를 가공해서 외부 데이터베이스에 저장이 주 역할
- **쿼리 엔진** : 분산 스토리지 상의 데이터를 SQL로 집계하기 위함, ex) Hive
- **ETL 프로세스** : 외부의 데이터 웨어하우스 제품 이용에 적합한 데이터 형식으로 변환하기 위한 일련의 절차(**추출(Extract), 가공(Transform), 로드(Load)**)
<br>
<br>

### 6) 워크플로 관리
- 전체 데이터 파이프라인의 동작을 관리하기 위함
- 매일 정해진 시간에 스케줄대로 배치 처리 실행 및 오류 발생 시 관리자에게 통지하는 목적으로 사용
- 데이터 파이프라인이 복잡해짐에 따라 한 곳에서 제어하여 전체의 움직임을 파악하는 것이 중요
- 크건 작건 시스템 장애가 발생 시의 처리와 다시 처리하기 위한 기능 필수
<br>
<img height=400 src="https://user-images.githubusercontent.com/83000975/164909198-53e772ac-fd78-4b21-8da4-6a4e9db69b0f.jpeg">
<sub><b>[ETL 프로세스]</b></sub>
<br>
<br>

## 데이터 웨어하우스와 데이터 마트
### - 데이터 파이프라인 기본형
<img height=400 src="https://user-images.githubusercontent.com/83000975/164968316-f1945c3c-8519-4d84-b326-3d2b46c26cb7.jpeg">
<sub><b>[데이터 웨어하우스를 중심으로 하는 데이터 파이프라인]</b></sub>

- 대량의 데이터 장기보존에 최적(소량의 데이터를 자주 쓰고 읽는 데는 부적합)
- 전형적인 사용방법 : 하루가 끝날 때 데이터를 정리 -> 야간 시간대에 집계해서 보고서 작성
- **데이터 소스** : 업무 시스템을 위한 RDB나 로그 등을 저장하는 파일 서버
- **로우 데이터** : 데이터 소스에 보존된 원시 데이터
- **ETL 프로세스** : 로우 데이터를 추출 가공하여 데이터 웨어하우스에 저장하기까지의 흐름(웨어하우스 구축에 'ETL 도구' 소프트웨어가 자주 이용)
- **데이터 마트** : 데이터 분석과 같은 목적에 사용하는 경우에만 데이터 웨어하우스에서 데이터를 추출하여 구축(데이터 시각화에 BI와 함꼐 이용되기도 함)
<br>
<br>

## 데이터 레이크
### - 데이터를 그대로 축적
- **데이터 레이크** : 데이터를 축적하는 호수
- 분산 스토리지가 데이터 레이크에 이용 됨
- 데이터 형식은 자유지만 CSV나 JSON같은 범용적인 텍스트 형식을 사용
<br>
<img height=400 src="https://user-images.githubusercontent.com/83000975/164971350-1b5b04a5-38f7-4266-a80c-9ee12887f5b8.jpeg">

<sub><b>[데이터 레이크의 이미지]</b></sub>
<br>
<img height=400 src="https://user-images.githubusercontent.com/83000975/164971360-80caa358-352a-402e-94a7-5d49b3bd65ac.jpeg">

<sub><b>[데이터 레이크를 중심으로 하는 데이터 파이프라인]</b></sub>
<br>
<br>

### 데이터 레이크와 데이터 마트 - 필요한 데이터는 데이터 마트에 정리
- 데이터 레이크는 단순한 스토리지(데이터를 가공할 수 없음)이므로 MapReduce 등의 분산 데이터 처리 기술을 사용
- 데이터를 가공, 집계, 데이터 마트로 추출 후 데이터 분석 진행 가능
<br>
<br>

## 데이터 분석 기반을 단계적으로 발전시키기
### - 팀과 역할 분담, 스몰 스타트와 확장
- 데이터 분석에 필요한 기술이 다방면에 걸쳐 있기 때문에 팀을 이루어 작업
- **데이터 엔지니어(data engineer)** : 시스템의 구축 및 운용, 자동화를 담당
- **데이터 분석가(data analyst)** : 데이터에서 가치 있는 정보를 추출
<br>
<br>

### 1) 애드 혹 분석 및 대시보드 도구
- **애드 혹 분석** : 일회성 데이터 분석(ex. SQL쿼리를 직접 작성해서 실행, 스프레드시트에서 그래프 작성)
- 데이터 마트를 만들지 않은 채 데이터 레이크와 데이터 웨어하우스에 직접 연결하여 사용하는 경우가 다수
- 결과를 즉시 확인할 수 있도록 대화형 분석 도구를 사용
- **대시보드 도구** : 그래프와 보고서를 만들기 위해서 사용
<br>
<img height=400 src="https://user-images.githubusercontent.com/83000975/164971910-81d4b119-b7e1-408d-9722-702b8c70d85d.jpeg">

<sub><b>[데이터 분석 기반의 발전]</b></sub>
<br>
<br>

### 2) 데이터 마트와 워크플로 관리
- 시각화에 BI도구를 사용할 경우 집계 속도를 높이기 위해서는 데이터 마트 구축이 필수
- 데이터 마트 구축은 배치 처리로 자동화되는 경우가 많기에 워크플로 관리 도구를 사용
- 데이터 처리를 자동화하여 장기적으로 운용해 나가기 위해서는 안정된 워크플로 관리 필수
<br>
<br>

## 데이터를 수집하는 목적
### - '검색', '가공', '시각화'의 세 가지 예
- 데이터를 모은 후에 무엇을 실시할지는 달성하고자 하는 목적에 따라 달라짐
<img height=400 src="https://user-images.githubusercontent.com/83000975/164972322-da2bdb16-f1e7-4ca2-87e8-092f61e53c5b.jpeg">

<sub><b>[데이터 이용 목적의 예]</b></sub>
<br>
<br>

### 1) 데이터 검색
- 언제 무엇이 필요할지 모르기 때문에 시스템 로그 및 고객의 행동 이력 등 발생하는 모든 데이터 취득
- 신속하게 검색할 수 있도록 하기 위해 실시간 데이터 처리나 검색 엔진을 사용하여 키워드를 찾는 기능 필요
<br>
<br>

### 2) 데이터의 가공
- 데이터 가공에는 자동화가 필수
- 워크플로 관리를 도입하여 시스템을 구축
- 데이터 분석보다는 시스템 개발 영역에 더욱 가까움
<br>
<br>

### 3) 데이터 시각화
- 상황을 예측해 의사 결정에 도움이 필요한 경우에 필요
- 데이터의 시각화를 위해선 데이터 마트 필요
- 대시보드에 집계 결과를 정리해 변화를 감시하고 싶을 때도 데이터 시각화가 필요
<br>
<br>

## 확증적 데이터 분석과 탐색적 데이터 분석
- **확증적 데이터 분석** : 데이터 분석이란 가설을 세우고 검증하는 것(통계학적 모델링)
- **탐색적 데이터 분석** : 데이터를 보면서 그 의미를 읽어내려고 하는 것(데이터를 시각화하여 사람의 힘으로 의미를 분석)
