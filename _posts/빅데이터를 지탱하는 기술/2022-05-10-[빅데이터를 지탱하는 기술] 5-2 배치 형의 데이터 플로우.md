---
layout : post
title : '[빅데이터를 지탱하는 기술] 5-2 배치 형의 데이터 플로우'
subtitle : '[빅데이터를 지탱하는 기술] 정리'
gh-repo: junhong625/Study
gh-badge: [star, fork, follow]
tags : [빅데이터를 지탱하는 기술, Study]
comments: true
---

# 5-2 배치 형의 데이터 플로우
- - - 

## MapReduce의 시대는 끝났다 - 데이터 플로우와 워크플로
- `데이터 플로우(data flow)` : 다단계의 데이터 처리를 그대로 분산 시스템의 내부에서 실행하는 것
    - 장점 : 
        - 데이터 파이프라인을 DAG로 조립하고 나서 실행에 옮김으로써 내부 스케줄러가 분산 시스템에 효과적인 실행 계획을 세워준다.
        - 텍스트 데이터의 가공이나 열 지향 스토리지로의 변환 등의 부하가 큰 처리를 할 수 있다.

|명칭|개발원|
|:--|:--|
|Google Cloud Dataflow|Google|
|Apache Spark|The Apache Software Foundation|
|Apache Flink|The Apache Software Foundation|

[데이터 플로우를 위한 프레임워크]
<br>
<br>

### MapReduce의 구조
- 구조 : 
    1. 분할된 데이터를 처리하는 첫 번째 단계 - **Map**
    2. 결과를 모아서 집계하는 두 번째 단계 - **Reduce**
- 한때 빅데이터의 대표적인 기술이었지만 현재는 대체할 기술들이 많이 나왔다.
- **Google Cloud Dataflow**에서 사용 중인 **MillWheel**, **Hadoop**의 **Tez**와 **Spark**까지 대체할 많은 프레임워크가 나왔다.
<br>
<br>

## MapReduce를 대신할 새로운 프레임워크 - DAG에 의한 내부 표현
- 새로운 프레임워크에는 공통적으로 `DAG`라 불리는 데이터 구조가 들어간다
    - `DAG(directed acyclic graph)` : 방향성 비순환 그래프
        - 특성 :
            - 노드와 노드가 화살표로 연결된다.(**방향성**)
            - 화살표를 아무리 따라가도 동일 노드로는 되돌아오지 않는다.(**비순환**)
- **데이터 플로우**에서는 실행해야할 일련의 태스크를 **DAG**에 의한 데이터 구조로 표현한다.
    - 데이터 플로우에서는 DAG를 구성하는 각 노드가 모두 동시 병행으로 실행된다.(MapReduce에서 발생하던 대기시간을 없앤다.)

<img height=400 src="https://user-images.githubusercontent.com/83000975/168739778-7f1c1499-bfc7-4703-8c97-6977a30ec1ce.jpeg">
<sub><b>[DAG의 예]</b></sub>

- 기존의 MapReduce도 Map과 Reduce의 두 종류의 노드로 이루어진 간단한 DAG라고 할 수 있다.
    - 하지만 하나의 노드에서 처리가 끝나지 않으면 다음 처리로 진행할 수 없어 비효율적이다.
<br>
<br>

### Spark에 있어서의 DAG
- Spakr와 같은 데이터 플로우의 프레임워크에서는 프로그래밍 언어를 사용하여 직접 DAG의 데이터 구조를 조립한다.
```python
# 파일로부터 데이터를 읽어 들인다.
lines = sc.textFile("sample.txt")

# 파일의 각 행을 단어로 분해
words = lines.flatMap(lambda line: line.split())

# 단어마다의 카운터를 파일에 출력
words.map(lambda word: (word, 1)) \
     .reduceByKey(lambda a, b: a + b) \
     .saveAsTextFile("word_counts") # 여기서 실행 개시
```
<sub><b>[Spark(배치형) 프로그램]</b></sub>

- DAG에 의한 프로그래밍의 특징 : `지연 평가`
    - `지연 평가(lazy evaluation)` : 계산이 필요할 때까지 계산을 늦추는 기법으로 DAG를 구축하고 실행 결과를 요구해야 데이터 처리가 시작된다.
        - 장점 : 
            1. 불필요한 계산을 하지 않으므로 빠른 계산이 가능하다.
            2. 무한 자료 구조를 사용 할 수 있다.
            3. 복잡한 수식에서 오류 상태를 피할 수 있다.


<br>
<br>

## 데이터 플로우와 워크플로를 조합하기
- 데이터 플로우에서 프로그래밍을 하고 데이터의 입출력을 하나의 DAG로 기술하면 워크플로 없이도 실행가능한 데이터 파이프라인을 구성할 수 있다.
    - 하지만 태스크를 정기적으로 실행하거나 실패한 태스크를 기록하여 복구하는 것은 데이터 플로우가 아닌 워크플로에서만 가능하다.
    - 따라서, 데이터 플로우의 프로그램도 워크플로의 일부로서 실행되는 하나의 태스크로 고려할 수 있다.
<br>
<br>

### [데이터 입출력] 데이터를 읽어들이는 플로우
- 데이터를 읽어 들이기 위한 워크플로 구성 과정(데이터 플로우 사용) : 
    1. 데이터 플로우로부터 읽어 들일 데이터는 성능적으로 안정된 분산 스토리지에 배치하도록 한다.
        - 플로우가 완성될 때까지의 개발 중에는 동일 데이터를 여러 번 읽어들여 테스트하므로 분산 스토리지에 복사된 데이터만을 이용한다.
    2. 외부의 데이터 소스에서 데이터를 읽어 들일 때는 벌크 형의 전송 도구로 태스크를 구현한다.
        - 데이터 소스로부터의 읽어들이기에서 발생하는 오류에 대해 대처하기 위해 워크플로 관리 도구를 사용하는 것이 적합하다.
    3. 데이터의 가공, 열 지향 스토리지로의 변환 등 부하가 큰 처리를 데이터 플로우에서 실행한다. 
<br>
<br>

### [데이터 입출력] 데이터를 써서 내보내는 플로우
- 데이터의 집계 결과를 외부 시스템에 내보내는 경우에는 반대의 관계가 된다.
- 데이터 플로우 안에서 대량의 데이터를 외부에 전송하는 것은 피해야 한다.
- 데이터를 내보내기 위한 워크플로 구성 과정(데이터 플로우 사용) : 
    1. 데이터 플로우의 출력을 CSV 파일로 변환하여 분산 스토리지에 넣는다.
    2. 벌크 형의 전송 도구를 사용하여 태스크를 구현하거나 외부 시스템 쪽에서 파일을 읽어 들이도록 지시한다.
        - MPP 데이터베이스를 이용하면 분산 스토리지로부터 파일을 로드하는 명령어를 발행할 수 있다.
<br>
<br>

## 데이터 플로우와 SQL을 나누어 사용하기 - 데이터 웨어하우스의 파이프라인과 데이터 마트의 파이프라인
- 위의 데이터 입출력 과정에 SQL에 의한 쿼리의 실행까지를 조합시킴으로써 배치형의 데이터 파이프라인을 완성시킬 수 있다.
- 데이터 분석을 위해 SQL로 쿼리를 실행시킬 때 **데이터 웨어하우스의 파이프라인**과 **데이터 마트의 파이프라인** 두 가지 구성 방법 중 하나를 선택할 수 있다.
    1. **데이터 웨어하우스의 파이프라인(MPP 데이터베이스에서 실행하는 경우)** 
        <img height=300 src="https://user-images.githubusercontent.com/83000975/168745034-081edc86-dae7-4c5b-8022-655f17ddc6d9.jpg">
        - 로드되는 데이터를 만드는 부분까지가 데이터 플로우의 역할
            - 비구조화 데이터를 가공하여 분산 스토리지에 써넣는다.

    2. **데이터 마트의 파이프라인(쿼리 엔진에서 실행하는 경우)**
        <img height=300 src="https://user-images.githubusercontent.com/83000975/168745244-7c0f131d-3b94-40ee-8506-8aa6275ab537.jpg">
        - 구조화 데이터를 만드는 부분까지가 데이터 플로우의 역할
            - 분산 스토리지 상의 데이터를 매일 반복되는 배치로 가공하여 열 지향의 스토리지 형식으로 보관해둔다.
<br>
<br>

### 대화식 플로우 - 애드 혹 분석의 파이프라인
- 애드 혹 데이터 분석에서는 위의 파이프라인들과는 또 다른 파이프라인 된다.
- 원래 애드 혹 분석에서는 많은 데이터 처리를 수작업으로 시행하므로 워크플로는 필요하지 않다.
    - 하지만 아직 구조화 되지 않은 데이터를 애드 혹 분석할 때에는 데이터 플로우가 매우 유용하다.
    - 로우 데이터에 직접 접속하여 스크립트 언어를 사용하여 데이터를 가공, 집계할 수 있고 데이터 구조화를 끝낸 후 집계를 고속 처리가 가능하기 떄문이다.
- 분석하고 싶은 데이터가 이미 구조화되어 있는 경우는 쿼리 엔진을 사용해 참조한다.
    - 단, 쿼리 엔진과 시각화 도구와의 조합은 무수히 많이 존재하나 안정적인 접속을 할 수 없는 경우도 있으니 안정적인 워크플로 운용을 추구할 경우에는 RDB와 MPP 데이터베이스를 데이터마트로 하는 편이 확실하다.
    