---
layout : post
title : '[빅데이터를 지탱하는 기술] 5-3 스트리밍 형의 데이터 플로우'
subtitle : '[빅데이터를 지탱하는 기술] 정리'
gh-repo: junhong625/Study
gh-badge: [star, fork, follow]
tags : [빅데이터를 지탱하는 기술, Study]
comments: true
---

# 5-3 스트리밍 형의 데이터 플로우
- - - 

## 배치 처리와 스트림 처리로 경로 나누기
- **배치 처리**를 중심으로 하는 데이터 파이프라인 : 
    - 데이터를 분석할 수 있게 되기까지의 시간이 오래 걸린다.
    - 집계 효율을 높이기 위해 열 지향 스토리지로 변환하는데 시간이 필요하기 때문이다.
    - 데이터가 영구적으로 보존된다.
    - 장기적인 데이터 분석에 적합하다.
- **스트림 처리(streaming processing)**를 중심으로 하는 데이터 파이프라인 : 
    - 분산 스토리지를 거치지 않고 데이터 처리를 한다.
    - 처리한 결과를 시계열 데이터 보관에 적합한 스토어에 보관하거나 실시간 시스템에 전송한다.
    - 실시간에 가까운 데이터 처리를 하기에 적합하다.

- 데이터 처리 시 **배치 처리**와 **스트림 처리** 각각의 특징과 용도에 맞게 적합한 경로로 설정해줘야 한다.
<br>
<br>

## 배치 처리와 스트림 처리 통합하기
- 배치 처리에서는 데이터를 작게 나눠 DAG를 구성하고 스트림 처리에서는 실시간으로 계속 들어오는 데이터가 DAG 안에 흘러들어옴에 따라 처리가 진행된다.
<img height=400 src="https://user-images.githubusercontent.com/83000975/168995265-8d3acba8-e0f0-40d8-adbc-67593b4235ab.jpeg">
<sub><b>[스트림 처리와 배치 처리의 차이]</b></sub>

- `유한 데이터(bounded data)` : 배치 처리와 같이 실행 시에 데이터양이 정해지는 것
- `무한 데이터(unbounded data)` : 스트림 처리와 같이 제한이 없이 데이터가 보내지는 것
- `유한 데이터(bounded data)`와 `무한 데이터(unbounded data)`의 공통점 : 
    - 데이터를 작게 분할해서 DAG에서 실행한다
- 공통점으로 인해 DAG를 사용한 데이터 플로우에서는 배치 처리와 스트림 처리를 동일하게 프로그래밍 하는 것이 가능하다.
<br>
<br>

### Spark 스트리밍의 DAG
- Spark는 배치 처리를 위한 분산 시스템이나 **Spark 스트리밍(Spark streaming)**이라는 기능이 통합됨으로써 스트림 처리까지 가능한 프레임워크가 되었다.

``` python
# 1초마다 스트림 처리를 한다.
sc = SparkContext("local[2]", "NetworkWordCount")
ssc = StreamingContext(sc, 1)

# TCP 포트 9999로부터 데이터를 읽어 들인다.
lines = ssc.socketTextStream("localhost", 9999)

# 입력의 각 행을 단어로 분해한다.
words = lines.flatMap(lambda line: line.split())

# 단어별 갯수를 콘솔에 출력한다.
words.map(lambda word: (word, 1)) \
     .reduceByKey(lambda a, b: a + b)
     .pprint()

# 스트림 처리를 시작한다.
ssc.start()
```
<sub><b>[Spark 스트리밍 프로그램]</b></sub>

- 이전 장에서 기술했던 배치 처리의 스크립트와 비교하면 데이터를 읽고 쓰는 초기화 부분에 차이가 있을 뿐 데이터 처리의 중심부(**Map**처리와 **Reduce**처리)는 똑같다는 것을 알 수 있다.
- **이렇게 하나의 프레임 워크에서 통합적인 데이터 처리를 기술할 수 있다는 점**이 **데이터 플로우의 장점**
<br>
<br>

## 스트림 처리의 결과를 배치 처리로 치환하기 - 스트림 처리의 두 가지 문제에 대한 대처
- 스트림 처리의 잠재적인 문제점 두 가지 :
    1. 틀린 결과를 어떻게 수정할 것인가?
        - 스트림 처리는 원칙적으로 새롭게 도달한 데이터를 처리할 뿐, 시간을 되돌린다는 개념은 없다.
    2. 늦게 전송된 데이터 취급을 어떻게 할 것인가?
        - 메시지 배송에는 지연이 발생하는 법인데 집계가 끝난 후에 도착한 데이터도 있으므로 스트림 처리는 부정확해질 수밖에 없다.

### 해결법 1) 람다 아키텍처 - 배치 레이어, 서빙 레이어, 스피드 레이어
- `람다 아키텍처(lambda architecture)` : 대량의 데이터를 실시간으로 분석하기 어려우니 batch로 미리 만든 데이터와 실시간 데이터를 혼합해서 사용하는 방식이다.
- 람다 아키텍쳐는 데이터 파이프라인을 3개의 레이어로 구분한다.
- 람다 아키텍처 작업 순서 : 
    1. 모든 데이터는 반드시 `배치 레이어(batch layer)`에서 처리한다.
        - 과거의 데이터를 장기적인 스토리지에 축적하고 여러 번이고 다시 집계할 수 있게 한다.
        - 배치 레이어는 대규모 배치 처리를 실행할 수 있는 반면에, 1회 처리에는 긴 시간이 걸린다.
    2. 배치 처리 결과는 `서빙 레이버(serving layer)`를 통해서 접근한다.
        - 서빙 레이어에 응답이 빠른 데이터베이스를 설치하여 집계 결과를 바로 추출한다.
    3. 서빙 레이어에서 얻어진 결과를 `배치 뷰(batch view)`라고 한다.
        - 배치 뷰는 정기적으로 업데이트되지만, 실시간 정보를 얻을 수 없다.
    4. 그러므로 다른 경로로 스트림 처리를 하기 위해 `스피드 레이어(speed layer)`를 설치한다.
    5. 스피드 레이어에서 얻은 결과를 `실시간 뷰(realtime view)`라고 한다.
        - 실시간 뷰는 배치 뷰가 업데이트될 동안까지만 이용되고, 오래된 데이터는 순서대로 삭제된다.
    6. 마지막으로, 배치 뷰와 실시간 뷰 모두를 조합시키는 형태로 쿼리를 실행한다.
        - 이 조합에 의해 배치 처리와 스트림 처리의 결점을 보완한다.
- 장점 : 
    - **실시간 뷰**의 결과는 나중에 **배치 뷰**로 치환된다.
    - 즉, 스트림 처리의 결과는 일시적으로 사용되고 잠시 기다리면 배치 처리에 의해 올바른 결과를 얻을 수 있다.
<br>
<br>

### 해결법 2) 카파 아키텍처
- **람다 아키텍처의 단점**을 대체하는 `카파 아키텍처`를 사용하는 것도 선택지 중 하나이다.
    - **람다 아키텍처의 단점** : 스피드 레이어와 배치 레이어는 모두 똑같은 배치 처리를 하고 있다.(나쁜 개발 효율)
    - `카파 아키텍처(kappa architecture)` : 람다 아키텍처에서 배치 레이어와 서빙 레이어를 완전히 제거하여 단순화한 아키텍처
        - 특징 : 
            - 메시지 브로커의 데이터 보간 기간을 충분히 길게하여 문제가 발생 시 메시지 배송 시간을 과거로 다시 설정한다.
            - 배치 처리와 같은 과거 데이터의 일괄 처리를 스트림 처리만으로 실행할 수 있다.
        - 문제점 : 
            - 대량의 데이터를 스트림 처리의 데이터 플로우에 보내기 때문에 부하가 높아진다.(현재 클라우드 서비스 보급 및 발전에 의해 자원확보가 수월해져 이전처럼 부하가 높지 않다.)
<br>
<br>

## 아웃 오브 오더의 데이터 처리
- `아웃 오브 오더(out of order)`의 데이터 문제 : 스트림 처리 시 발생하는 메시지 배송 문제 즉, 이벤트 시간과 프로세스 시간의 차이로 발생하는 문제
- `아웃 오브 오더(out of order)`의 데이터 문제를 해결하고 스트림 처리 시 올바른 집계 결과를 얻기 위해서 고려해야 할 점
    1. 원래 데이터의 모습은 **이벤트 시간**으로 얻을 수 있다.
        - 프로세스 시간으로 처리할 시 지연이 발생하면 실제로는 보내진 데이터양의 변화가 없음에도 시스템상의 이유로 집계 결과가 변한 것처럼 보일 수 있다.
    2. `이벤트 시간 윈도윙`을 고려해야 한다.
        - `윈도우(window)` : 스트림 처리에서 시간을 일정 간격으로 나누어 데이터를 집계하는 것
        - `이벤트 시간 윈도윙(event-time windowing)` : 이벤트 시간을 기준으로 윈도우를 나누는 것
        - 과거 이벤트의 상태를 보관하고 데이터가 도달할 때마다 해당 윈도우를 재집계한다.
        