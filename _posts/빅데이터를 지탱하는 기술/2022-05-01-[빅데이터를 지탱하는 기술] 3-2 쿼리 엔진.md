---
layout : post
title : '[빅데이터를 지탱하는 기술] 3-2 쿼리 엔진'
subtitle : '[빅데이터를 지탱하는 기술] 정리'
gh-repo: junhong625/Study
gh-badge: [star, fork, follow]
tags : [빅데이터를 지탱하는 기술, Study]
comments: true
---

# 3-2 쿼리 엔진
- - - 

## 데이터 마트 구축의 파이프라인
<img height=400 src="https://user-images.githubusercontent.com/83000975/166134388-6b2bed44-9106-4324-98ad-d0014b5d973e.jpeg">

<sub><b>[Hive와 Presto를 결합한 데이터 파이프라인]</b></sub>

1. 분산 스토리지에 저장된 데이터를 구조화하고 열 지향 스토리지 형식으로 저장함.(위 이미지의 ❶)
    - 다수의 텍스트 파일을 읽어 들여 가공하는 부하가 큰 처리가 되기 때문에 Hive를 이용함
2. 완성한 구조화 데이터를 결합, 집계하고 비정규화 테이블로 데이터 마트에 써서 내보냄(위 이미지의 ❷)
    - 열 지향 스토리지를 이용한 쿼리의 실행에는 Presto를 사용함으로써 실행 시간을 단축할 수 있음  
- **Hive 메타 스토어(Hive Metastore)** : Hive에서 만든 각 테이블의 정보가 저장되는 데이터베이스
    - Hive뿐만 아니라 다른 SQL-on-Hadoop의 쿼리 엔진에서도 공통의 테이블 정보로 참고됨
<br>
<br>

## Hive에 의한 구조화 데이터 작성
- **외부 테이블** : Hive의 외부에 있는 특정 파일을 참고해 마치 거기에 테이블이 존재하는 것처럼 읽어 들이기 위해 지정함
- Hive를 비롯한 대부분의 **SQL-on-Hadoop의 쿼리 엔진**은 MPP 데이터베이스처럼 데이터를 내부로 가져오지 않아도 텍스트 파일을 그대로 집계할 수 있음
    - 즉, 데이터를 그 자리에서 바로 집계할 수 있는 성질을 가지고 있어 애드 혹 데이터 분석에 유용함
    - 시간을 들여 데이터를 전송하지 않고도 원하는 정보를 얻을 수 있음
    - CSV파일을 그대로 집계하는 것은 비효율적임
        - 쿼리를 실행시킬 때마다 매번 텍스트를 읽어 들이기 때문에 확실히 빠르다고는 말할 수 없음
        - 이를 해결하기 위해 열 지향 스토리지로 변환
<br>
<br>

### 1) 열 지향 스토리지로의 변환 - 데이터 집계의 고속화(배치형 쿼리 엔진용)
- 테이블을 열 지향 스토리지 형식인 ORC 형식으로 변환
- ORC 형식으로의 변환에는 다소 시간이 걸리지만, 변환 후에는 파일 크기가 10분의 1로 줄어들며 테이블 집계까지의 시간도 줄어듬
- 텍스트 데이터를 열 지향 데이터로 변환함으로써 데이터의 집계가 크게 고속화됨
- 하지만 이것은 시간이 걸리는 프로세스이므로 Hive와 같은 배치형 쿼리 엔진에서 실행하는데 적합함
- 기존 데이터가 텍스트, 스키마리스 데이터든 간에 Hive에서 읽을 수 있는 형식이라면 쿼리를 조금 고쳐 쓰는 것만으로 어떤 테이블이라도 만들 수 있음
- **이것이 Hive를 이용한 데이터 구조화 프로세스임**
<br>
<br>

### 2) Hive로 비정규화 테이블을 작성하기
- 데이터의 구조화가 완료되면 다음은 데이터 마트의 구축 -> 즉, 테이블을 결합 및 집약해서 **비정규화 테이블**을 만듦
    - 이때 Presto와 같은 대화형 쿼리 엔진을 사용할 것인지 Hive 같은 배치형 쿼리 엔진을 사용할 것인지에 따라 달라짐
- 시간이 걸리는 배치 처리에는 원칙적으로 Hive를 사용해야 함
    - 예를 들어 비정규화 테이블이 수억 레코드나 되면 데이터 마트로 내보내는 것만으로도 상당한 시간이 소요될 것임
    - 이럴 경우에는 배치형 시스템을 사용하는 편이 리소스의 이용 효율의 높일 수 있음
- 비정규화 테이블을 만드는 데 오랜 시간이 걸리는 것은 흔한 일이며, 그렇기에 가능한 효율적인 쿼리를 작성해야 함
    - Hive의 쿼리를 개선하는 두 가지 예시 : 
        1. 서브 쿼리 안에서 레코드 수를 줄이는 방법 
        2. 데이터의 편향을 방지하는 방법
<br>
<br>

### 3) 서브 쿼리 안에서 레코드 수 줄이기 - 초기 단계에서 팩트 테이블 작게 하기
- Hive 쿼리는 SQL과 매우 유사하지만 특성은 일반적인 RDB와는 전혀 다름
- Hive는 데이터베이스가 아닌 **데이터 처리를 위한 배치 처리 구조**임
    - 읽어 들이는 데이터의 양을 의식하면서 쿼리를 작성하지 않으면 생각한 만큼의 성능이 나오지 않을 수 있음
    - 예시 :

``` SQL
-- 비효율적인 쿼리의 예
SELECT ...
FROM A
JOIN B on A.id = B.id
WHERE B.created_at = '2017-01-01'

-- 효율적인 쿼리의 예
SELECT ...
FROM (
    SELECT * A
    WHERE time >= TIMESTAMP '2017-01-01 00:00:00'
) A
JOIN B on A.id = B.id
WHERE B.created_at = '2017-01-01'
```

- 비효율적인 쿼리의 예 : 
    - 비효율적인 쿼리의 예를 보면 조건 없이 모든 데이터를 결합하고 이후에 나오는 WHERE에 의해 조건을 거쳐 검색을 하게 됨
    - 그 결과 대량의 중간 데이터가 생겨나지만 그 대부분을 버려 낭비가 큰 처리 과정이 됨(데이터의 양이 적다면 무시해도 큰 문제 없지만 대량의 데이터를 집계할 때는 이렇게 생겨나는 중간 데이터를 무시할 수 없음)
- 효율적인 쿼리의 예 :
    - 기본적으로 서브 쿼리 안에서 팩트 테이블을 작게 하는 것이 개선할 수 있는 확실한 방법임
    - Hive에서 최적화 해주는 경우도 있지만 그래도 가능하다면 본인이 의식해서 **초기에 팩트 테이블을 작게 하는 것**이 빅데이터의 집계에 있어서 중요함
<br>
<br>

### 4) 데이터 편향 피하기 - 분산 시스템의 성능 발휘를 위해
- 고속화를 방해하는 다른 하나의 문제는 **데이터의 편차(data skew)**임
    - 예를 들어 분산 시스템에서 SELECT count(distinct)를 실행하는 것은 다른 처리보다 오래 걸림.
    - 중복이 없는 값을 세려면 데이터를 한 곳에 모아야 하기에 분산 처리가 어려워지기 때문
    - 예시 : 

``` SQL
-- 비효율적인 쿼리의 예
SELECT date, count(distinct user_id) users
FROM access_log 
GROUP BY date

-- 효율적인 쿼리의 예
SELECT date, count(*) users
FROM (
    SELECT DISTINCT date, user_id FROM access_log
) t
GROUP BY date
```

- 분산 시스템의 성능을 발휘하기 위해서는 '효율적인 쿼리의 예'처럼 데이터의 편차를 최대한 없애고, 모든 노드에 데이터가 균등하게 분산되도록 해야함
<br>
<br>

## 대화형 쿼리 엔진 Presto의 구조 - Presto로 구조화 데이터 집계하기
- **대화형 쿼리 엔진** : 작은 쿼리를 여러 번 실행하는 대화형 데이터 처리에 적합하고 쿼리 실행의 지연을 감소시키는 것을 목적으로 개발된 기술
    - 이 분야에서 참고되는 기술은 2010년에 구글에서 발표한 **Dremel**임
    - **Dremel** : Google BigQuery의 핵심 기술 중 하나로, 수천 대의 컴퓨터에 분산된 열 지향 스토리지를 사용하여 집계를 가속화 함
        - Hive를 대체하는 대화형 쿼리 엔진으로 이용되고 있음

|시기|이벤트|
|:--|:--|
|2010년|Dremel 논문 발표|
|2010년|Google BigQuery 발표|
|2013년|Cloudera Impala 1.0 배포(현 Apache Impala)|
|2013년|Presto의 오픈 소스화|
|2015년|Apache Drill 1.0 배포|

<sub><b>[대표적인 대화형 쿼리 엔진]</b></sub>
<br>
<br>

### Presto의 특징 1) 플러그인 가능한 스토리지 - 하나의 쿼리 안에서 여러 데이터 소스에 연결 가능
- **Preto의 특징 중 하나** : 플러그인 가능한 스토리지 설계
<img height=400 src="https://user-images.githubusercontent.com/83000975/166137433-9a59ba52-0253-4d9a-b000-625ab8de0b4f.jpeg">

<sub><b>[Presto의 아키텍쳐]</b></sub>
- Presto의 아키텍쳐
    - Presto는 전용 스토리지를 갖고 있지 않아 Hive와 마찬가지로 다양한 데이터 소스에서 직접 데이터를 읽어 들임
    - Presto는 다수의 컴퓨터에서 실행되는 분산 시스템이며, 하나의 코디네이터와 여러 워커로 구성됨
    - 쿼리는 Presto CLI 등의 클라이언트에서 코디네이터로 전송됨. 코디네이터는 쿼리를 분석하고 실행 계획을 수립해 워커에게 처리를 분배함
- Presto는 'Hive Metastore'에 등록된 테이블을 가져올 수 있음
- CSV 같은 텍스트 데이터를 Presto에 가져올 수 있지만 Hive보다 특별히 뛰어난 것도 아님
- Presto가 최대 성능을 발휘하려면 원래 스토리지가 열 지향 데이터 구조로 되어 있어야함
    - Presto는 특히 ORC 형식의 로드에 최적화되어 있으며 그것을 확장성이 높은 분산 스토리지에 배치하여 최대의 성능을 발휘함
- 데이터의 로딩 속도를 높이려면 Presto 클러스터를 분산 스토리지와 네트워크의 가까운 곳에 설치한 후에 그것들을 가능한 한 고속 네트워크에 연결하도록 해야 함
- Hive에서 만든 구조화 데이터를 좀 더 집계하는 등의 목적에 적합함
- **Presto는 Hive 메타 스토어 이외에도 다양한 데이터 소스를 테이블로 참고할 수 있음**
    - ex) 하나의 쿼리 안에서 분산 스토리지 상의 팩트 테이블과 MySQL의 마스터 테이블을 조인할 수 있음, Cassandra와 같은 NoSQL DB에 저장된 데이터를 집계하고 싶을 때도 Presto가 도움이 됨
<br>
<br>

### 2) CPU 처리의 최적화 - 읽기와 코드 실행 병렬 처리
- Presto는 SQL의 실행에 특화된 시스템
    - 쿼리를 분석하여 최적의 실행 계획을 생성
    - 자바의 바이트 코드로 변환
        - 바이트 코드는 Presto의 워커 노드에 배포
    - 런타임 시스템에 의해 기계 코드로 컴파일 됨
- 코드의 실행은 멀티 스레드화되어 단일 머신에서 수백 태스크가 **병렬로 실행**됨
- 열 지향 스토리지에서의 읽기도 **병렬화**되어 데이터가 도달할 때마다 처리가 진행됨
- **Presto의 CPU 이용 효율이 높으므로 메모리와 CPU 리소스만 충분하다면 데이터의 읽기 속도가 쿼리의 실행 시간을 결정하게 됨**
- Presto 쿼리는 일단 실행이 시작되면 중간에 끼어들 수 없음
    - 너무 큰 쿼리를 실행하면 대부분의 리소스가 사용되어 다른 쿼리를 실행할 수 없게 될 우려가 있음
> 저자가 책을 집필할 당시에는 Presto가 YARN과 같은 리소스 매니저를 사용할 수 없었지만 제가 포스팅을 하고 있는 지금은 Presto에서 YARN을 사용할 수 있습니다.

<br>
<br>

### 3) 인 메모리 처리에 의한 고속화 - 쿼리 실행에는 가급적 대화형 쿼리 엔진 사용
- Presto는 Hive와 달리 쿼리 실행 과정에서 디스크에 쓰기를 하지 않음
    - 모든 데이터 처리를 메모리상에서 실시하고 메모리가 부족하면 여유가 생길 때까지 기다리거나 오류로 실패함
    - 이 경우 메모리 할당을 늘리거나 쿼리를 다시 작성해서 메모리 소비를 줄여야 함
- 취급하는 양이 많아도 그에 비례하여 메모리 소비가 늘어나는 것이 아님
    - ex) GROUP BY에 의한 데이터 집약은 단순한 반복 처리이므로 메모리 소비량은 고정임
- 대부분의 쿼리에 있어서 중간 데이터를 디스크에 쓰는 것은 쓸데없는 오버헤드 밖에 되지 않음
- 그렇기에 메모리상에서 할 수 있는 것은 메모리상에서 실행하고 디스크가 있어야 하는 일부 데이터 처리만을 Hive에 맡기는 것이 효과적임
- 즉, **대규모 배치 처리와 거대한 테이블끼리의 결합 : Hive를 활용** | **단시간 쿼리 실행 : Presto(대화형 쿼리 엔진)을 사용**와 같은 구조로 사용하는 것이 효율적임
<br>
<br>

### 4) 분산 결합과 브로드캐스트 결합
- 테이블의 결합은 종종 대량의 메모리를 소비함
- **분산 결합(distribute join)** : 둘 이상의 분할된 테이블을 결합하는 조인 절이 있는 SQL문
- Presto는 **분산 결합**을 실시하며 같은 키를 갖는 데이터는 동일한 노드에 모임
    - 분산 결합에서는 노드 간의 데이터 전송을 위한 네트워크 통신이 발송하기 때문에 종종 쿼리의 지연을 초래함
<img height=400 src="https://user-images.githubusercontent.com/83000975/166139019-13801f4e-0b01-44f6-8f92-d2e0a8f86231.jpeg">
<br>


- **브로드캐스트 결합(broadcast join)** : 두개의 테이블 중 작은 테이블을 executor에 복사하여 큰 테이블과 복사한 테이블을 조인
- 한쪽 테이블이 작은 경우에는 **브로드캐스트 결합**을 사용하여 처리 속도를 크게 고속화할 수 있음
    - 이 경우 결합하는 테이블의 모든 데이터가 각 노드에 복사됨
    - 스타 스키마처럼 하나의 팩트 테이블에 복수의 디멘전 테이블을 결합하는 경우에는 디멘전 테이블은 메모리에 충분히 들어갈 정도로 작은 것이 대부분임
    - 따라서 처음 한번만 복사하면 팩트 테이블을 재배치할 필요가 없어 테이블의 결합은 훨씬 빨라짐
- Presto에서 브로드캐스트 결합을 유효로 하려면 분산 결합을 명시적으로 무효화해야 함.
- 또한 쿼리 안의 SELECT 문으로 먼저 팩트 테이블을 지정하여 그것에 디멘전 테이블을 결합해야 함
<img height=400 src="https://user-images.githubusercontent.com/83000975/166139034-7ff55ab1-b908-442a-a2e8-2067860e0938.jpeg">
<br>
<br>

### 5) 열 지향 스토리지 집계
- **Presto에서는 열 지향 스토리지의 집계를 매우 빠르게 실행할 수 있음**
- 실제로 ORC 형식의 테이블을 로드해보면, 수백만 레코드 정도의 데이터를 1초 미만으로 집계할 수 있음
<br>
<br>

## 데이터 분석의 프레임워크 선택하기 - MPP 데이터베이스, Hive, Presto, Spark
### 1) MPP 데이터베이스 
- MPP 데이터베이스는 스토리지 및 계산 노드가 일체화되어 있어 처음에 ETL 프로세스 등으로 데이터를 가져오는 절차가 필요
    - 위 부분만 완성하면 SQL만으로 데이터를 집계할 수 있음
- 하지만 확장성 및 유연성 등의 측면에서는 분산시스템이 유리
    - '대량의 텍스트 처리', '데이터 처리를 프로그래밍', 'NoSQL 데이터베이스에 저장된 데이터를 집계' 이 3가지의 경우 분산 시스템의 프레임워크를 MPP 데이터베이스와 결합
- 시각화를 위한 데이터 마트에는 MPP 데이터베이스가 유력한 대안
    - BI 도구와 MPP 데이터베이스의 조합은 비정규화 테이블을 고속으로 집계하는 데에 최적
- **완성한 비정규화 테이블의 고속 집계에 적합함**
<br>
<br>

### 2) Hive
- 대규모 배처 처리를 꾸준히 실행함
- 텍스트 데이터를 가공하거나 열 지향 스토리지를 만드는 등의 무거운 처리 즉, 시간이 길어지는 처리에 Hive가 적합
- 데이터의 구조화에 적합
- Tez의 등장으로 대화형 쿼리에도 사용
    - Hive의 장점 : 안정성
- **데이터양에 좌우되지 않는 쿼리 엔진**
<br>
<br>

### 3) Presto
- 속도를 위해 다양한 것을 희생(Hive와 정반대의 쿼리 엔진)
- 쿼리 실행 중 오류가 발생하면 처음부터 다시 실행
    - 하지만 실행이 워낙 빠르기 떄문에 오류가 발생하면 다시 반복해서 사용
- 메모리가 부족하면 쿼리 실행할 수 없음
- 일상적인 데이터 분석을 위해 자주 사용되는 쿼리 엔진
- Hadoop, MySQL, 카산드라, 몽고DB 등 많은 데이터 스토어에 대응하고 있어 모든 데이터를 SQL로 집계하기 위한 중심적인 존재가 될 수 있음
- 대화식 쿼리의 실행에 특화되어 있어 텍스트 처리가 중심이 되는 ELT프로세스 및 데이터 구조화에는 적합하지 않음
    - 데이터의 구조화에는 Hive와 Spark를 사용하는 것이 적합
- Presto의 쿼리는 단시간에 대량의 리소스를 소비하기 때문에 무리해서 사용하면 다른 쿼리를 실행할 수 없음
- 시간이 걸리는 배치 처리는 Hive에 맡겨 Presto는 대화식 쿼리를 위해 여유를 갖게 하는 것이 좋음
- **속도 중시&대화식으로 특화된 쿼리 엔진**
<br>
<br>

### 4) Spark
- 인 메모리의 데이터 처리가 중심이며 Presto와 같이 대화형 쿼리 실행에 적합
- ETL 프로세스에서 SQL에 이르기까지의 일련의 흐름을 하나의 데이터 파이프라인으로 기술할 수 있는 것이 Spark의 장점
    - **Hive의 데이터 구조화**와 **Presto에 의한 SQL의 실행**을 Spark로는 하나의 스크립트 안에서 실행 가능
    - 즉, **텍스트 데이터를 읽어 들여 열 지향 스토리지로 변환 후 SQL로 집계해서 결과를 내보내는 일련의 프로세스**를 한 번의 데이터 처리로 기술할 수 있음
- ETL 프로세스, 머신러닝 같은 모든 데이터 처리에 사용할 수 있음
- 메모리 관리가 중요
- 데이터 처리를 일종의 프로그래밍으로 생각하고 그것을 위한 실행 환경에 적합
- **분산 시스템을 사용한 프로그래밍 환경**
